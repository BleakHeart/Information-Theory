{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class NaiveBayesClassifier():\n",
    "    '''\n",
    "    Bayes Theorem form\n",
    "    P(y|X) = P(X|y) * P(y) / P(X)\n",
    "    '''\n",
    "    def calc_prior(self, features, target):\n",
    "        '''\n",
    "        prior probability P(y)\n",
    "        calculate prior probabilities\n",
    "        '''\n",
    "        self.prior = (features.groupby(target).apply(lambda x: len(x)) / self.rows).to_numpy()\n",
    "\n",
    "        return self.prior\n",
    "    \n",
    "    def calc_statistics(self, features, target):\n",
    "        '''\n",
    "        calculate mean, variance for each column and convert to numpy array\n",
    "        ''' \n",
    "\n",
    "        self.mean = features.groupby(target).apply(np.mean).to_numpy()\n",
    "        self.var = features.groupby(target).apply(np.var).to_numpy()\n",
    "              \n",
    "        print(self.mean, self.var)\n",
    "        return self.mean, self.var\n",
    "    \n",
    "    def gaussian_density(self, class_idx, x):     \n",
    "        '''\n",
    "        calculate probability from gaussian density function (normally distributed)\n",
    "        we will assume that probability of specific target value given specific class is normally distributed \n",
    "        \n",
    "        probability density function derived from wikipedia:\n",
    "        (1/√2pi*σ) * exp((-1/2)*((x-μ)^2)/(2*σ²)), where μ is mean, σ² is variance, σ is quare root of variance (standard deviation)\n",
    "        '''\n",
    "        mean = self.mean[class_idx]\n",
    "        var = self.var[class_idx]\n",
    "        numerator = np.exp((-1/2)*((x-mean)**2) / (2 * var))\n",
    "#         numerator = np.exp(-((x-mean)**2 / (2 * var)))\n",
    "        denominator = np.sqrt(2 * np.pi * var)\n",
    "        prob = numerator / denominator\n",
    "        return prob\n",
    "    \n",
    "    def calc_posterior(self, x):\n",
    "        posteriors = []\n",
    "\n",
    "        # calculate posterior probability for each class\n",
    "        for i in range(self.n_classes):\n",
    "            prior = np.log(self.prior[i]) ## use the log to make it more numerically stable\n",
    "            conditional = np.sum(np.log(self.gaussian_density(i, x))) # use the log to make it more numerically stable\n",
    "            posterior = prior + conditional\n",
    "            posteriors.append(posterior)\n",
    "        # return class with highest posterior probability\n",
    "        return self.classes[np.argmax(posteriors)]\n",
    "     \n",
    "\n",
    "    def fit(self, features, target):\n",
    "        self.classes = np.unique(target)\n",
    "        self.n_classes = len(self.classes)\n",
    "        self.feature_nums = features.shape[1]\n",
    "        self.rows = features.shape[0]\n",
    "        \n",
    "        self.calc_statistics(features, target)\n",
    "        self.calc_prior(features, target)\n",
    "        \n",
    "    def predict(self, features):\n",
    "        preds = [self.calc_posterior(f) for f in features.to_numpy()]\n",
    "        return preds\n",
    "\n",
    "    def accuracy(self, y_test, y_pred):\n",
    "        return np.sum(y_test == y_pred) / len(y_test)\n",
    "\n",
    "    def visualize(self, y_true, y_pred, target):\n",
    "        \n",
    "        tr = pd.DataFrame(data=y_true, columns=[target])\n",
    "        pr = pd.DataFrame(data=y_pred, columns=[target])\n",
    "        \n",
    "        \n",
    "        fig, ax = plt.subplots(1, 2, sharex='col', sharey='row', figsize=(15,6))\n",
    "        \n",
    "        sns.countplot(x=target, data=tr, ax=ax[0], palette='viridis', alpha=0.7, hue=target, dodge=False)\n",
    "        sns.countplot(x=target, data=pr, ax=ax[1], palette='viridis', alpha=0.7, hue=target, dodge=False)\n",
    "        \n",
    "\n",
    "        fig.suptitle('True vs Predicted Comparison', fontsize=20)\n",
    "\n",
    "        ax[0].tick_params(labelsize=12)\n",
    "        ax[1].tick_params(labelsize=12)\n",
    "        ax[0].set_title(\"True values\", fontsize=18)\n",
    "        ax[1].set_title(\"Predicted values\", fontsize=18)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width  species\n",
       "0           5.1          3.5           1.4          0.2        0\n",
       "1           4.9          3.0           1.4          0.2        0\n",
       "2           4.7          3.2           1.3          0.2        0\n",
       "3           4.6          3.1           1.5          0.2        0\n",
       "4           5.0          3.6           1.4          0.2        0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = sns.load_dataset(\"iris\")\n",
    "\n",
    "dic = {'setosa': 0, 'versicolor': 1, 'virginica': 2}\n",
    "df['species'] = df['species'].map(dic)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df, class_feature):\n",
    "    n_classes = df[class_feature].unique().size\n",
    "    train_list = []\n",
    "    test_list = []\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        df_sliced = df[df['species'] == i]\n",
    "        n_rows = df_sliced.shape[0]\n",
    "        train_list.append(df_sliced.iloc[:n_rows // 2, :])\n",
    "        test_list.append(df_sliced.iloc[n_rows // 2 :, :])\n",
    "\n",
    "    train_df = pd.concat(train_list).reset_index(drop=True)\n",
    "    test_df = pd.concat(test_list).reset_index(drop=True)\n",
    "\n",
    "    X_train = train_df.iloc[:, :-1].to_numpy()\n",
    "    y_train = train_df.iloc[:, -1].to_numpy()\n",
    "\n",
    "    X_test = test_df.iloc[:, :-1].to_numpy()\n",
    "    y_test = test_df.iloc[:, -1].to_numpy()\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split(df, 'species')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB = NaiveBayesClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.006 3.428 1.462 0.246 0.   ]\n",
      " [5.936 2.77  4.26  1.326 1.   ]\n",
      " [6.588 2.974 5.552 2.026 2.   ]] [[0.121764 0.140816 0.029556 0.010884 0.      ]\n",
      " [0.261104 0.0965   0.2164   0.038324 0.      ]\n",
      " [0.396256 0.101924 0.298496 0.073924 0.      ]]\n"
     ]
    }
   ],
   "source": [
    "NB.fit(df, 'species')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.NaiveBayesClassifier at 0x1036ddbb0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
